[
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "protocol_codes",
        "description": "protocol_codes",
        "isExtraImport": true,
        "detail": "protocol_codes",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "gensim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gensim",
        "description": "gensim",
        "detail": "gensim",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DATA_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DOCUMENTS_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DOCUMENTS_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DATA_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DATA_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DATA_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DATA_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DOCUMENTS_UBICATION",
        "importPath": "Pre_Processing.Document",
        "description": "Pre_Processing.Document",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "read_documents",
        "importPath": "Pre_Processing.Document_Folder_Access",
        "description": "Pre_Processing.Document_Folder_Access",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document_Folder_Access",
        "documentation": {}
    },
    {
        "label": "read_documents",
        "importPath": "Pre_Processing.Document_Folder_Access",
        "description": "Pre_Processing.Document_Folder_Access",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document_Folder_Access",
        "documentation": {}
    },
    {
        "label": "clean_document",
        "importPath": "Pre_Processing.Document_Cleaner",
        "description": "Pre_Processing.Document_Cleaner",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "clean_document",
        "importPath": "Pre_Processing.Document_Cleaner",
        "description": "Pre_Processing.Document_Cleaner",
        "isExtraImport": true,
        "detail": "Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "build_words_id_dictionary",
        "importPath": "Pre_Processing.Word_Id_Dictionary",
        "description": "Pre_Processing.Word_Id_Dictionary",
        "isExtraImport": true,
        "detail": "Pre_Processing.Word_Id_Dictionary",
        "documentation": {}
    },
    {
        "label": "spacy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "spacy",
        "description": "spacy",
        "detail": "spacy",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "build_tf_idf_model",
        "importPath": "Pre_Processing.TF_IDF",
        "description": "Pre_Processing.TF_IDF",
        "isExtraImport": true,
        "detail": "Pre_Processing.TF_IDF",
        "documentation": {}
    },
    {
        "label": "build_similarity_matrix",
        "importPath": "Pre_Processing.Similarity_Matrix",
        "description": "Pre_Processing.Similarity_Matrix",
        "isExtraImport": true,
        "detail": "Pre_Processing.Similarity_Matrix",
        "documentation": {}
    },
    {
        "label": "build_doc_term_matrix",
        "importPath": "Pre_Processing.Doc_Term_Matrix",
        "description": "Pre_Processing.Doc_Term_Matrix",
        "isExtraImport": true,
        "detail": "Pre_Processing.Doc_Term_Matrix",
        "documentation": {}
    },
    {
        "label": "Corpus",
        "importPath": "Pre_Processing.Corpus",
        "description": "Pre_Processing.Corpus",
        "isExtraImport": true,
        "detail": "Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "load_all_dates",
        "importPath": "Pre_Processing.Corpus",
        "description": "Pre_Processing.Corpus",
        "isExtraImport": true,
        "detail": "Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "save_all_dates",
        "importPath": "Pre_Processing.Corpus",
        "description": "Pre_Processing.Corpus",
        "isExtraImport": true,
        "detail": "Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "Corpus",
        "importPath": "Pre_Processing.Corpus",
        "description": "Pre_Processing.Corpus",
        "isExtraImport": true,
        "detail": "Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "load_all_dates",
        "importPath": "Pre_Processing.Corpus",
        "description": "Pre_Processing.Corpus",
        "isExtraImport": true,
        "detail": "Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "utils",
        "description": "utils",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "ir_datasets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ir_datasets",
        "description": "ir_datasets",
        "detail": "ir_datasets",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "add_random_documents",
        "importPath": "To_Test.documents",
        "description": "To_Test.documents",
        "isExtraImport": true,
        "detail": "To_Test.documents",
        "documentation": {}
    },
    {
        "label": "process_documents",
        "importPath": "Pre_Processing.Processor",
        "description": "Pre_Processing.Processor",
        "isExtraImport": true,
        "detail": "Pre_Processing.Processor",
        "documentation": {}
    },
    {
        "label": "prepare_corpus",
        "importPath": "Pre_Processing.Processor",
        "description": "Pre_Processing.Processor",
        "isExtraImport": true,
        "detail": "Pre_Processing.Processor",
        "documentation": {}
    },
    {
        "label": "search",
        "importPath": "Search.Search",
        "description": "Search.Search",
        "isExtraImport": true,
        "detail": "Search.Search",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "zmq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zmq",
        "description": "zmq",
        "detail": "zmq",
        "documentation": {}
    },
    {
        "label": "ChordNodeReference",
        "kind": 6,
        "importPath": "distributed.chord",
        "description": "distributed.chord",
        "peekOfCode": "class ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n    # Internal method to send data to the referenced node\n    def _send_data(self, op: int, data: str = None) -> bytes:\n        print(f'mandando la data con op{op} - y data {data}')\n        try:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:",
        "detail": "distributed.chord",
        "documentation": {}
    },
    {
        "label": "ChordNode",
        "kind": 6,
        "importPath": "distributed.chord",
        "description": "distributed.chord",
        "peekOfCode": "class ChordNode:\n    def __init__(self, ip: str, port: int = 8001, m: int = 160): #m=160\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n        self.ref:ChordNodeReference = ChordNodeReference(self.ip, self.port)\n        self.succ:ChordNodeReference = self.ref  # Initial successor is itself\n        self.pred:ChordNodeReference = None  # Initially no predecessor\n        self.m = m  # Number of bits in the hash/key space\n        self.finger = [self.ref] * self.m  # Finger table",
        "detail": "distributed.chord",
        "documentation": {}
    },
    {
        "label": "getShaRepr",
        "kind": 2,
        "importPath": "distributed.chord",
        "description": "distributed.chord",
        "peekOfCode": "def getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n    # Internal method to send data to the referenced node\n    def _send_data(self, op: int, data: str = None) -> bytes:",
        "detail": "distributed.chord",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "distributed.chord",
        "description": "distributed.chord",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port",
        "detail": "distributed.chord",
        "documentation": {}
    },
    {
        "label": "serialize_logs",
        "kind": 2,
        "importPath": "distributed.logguer",
        "description": "distributed.logguer",
        "peekOfCode": "def serialize_logs(logs_json, filename=\"logs.json\"):\n    with open(filename, 'w') as f:\n        json.dump(logs_json, f, indent=4)\n# Crea una función para registrar mensajes con información adicional\ndef log_message(message, level=\"INFO\", extra_data={}):\n    \"\"\"\n    Registra un mensaje de log con información adicional.\n    \"\"\"\n    log_entry = {\n        \"timestamp\": datetime.now().isoformat(),",
        "detail": "distributed.logguer",
        "documentation": {}
    },
    {
        "label": "log_message",
        "kind": 2,
        "importPath": "distributed.logguer",
        "description": "distributed.logguer",
        "peekOfCode": "def log_message(message, level=\"INFO\", extra_data={}):\n    \"\"\"\n    Registra un mensaje de log con información adicional.\n    \"\"\"\n    log_entry = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"level\": level,\n        \"message\": message,\n        \"extra_data\": extra_data\n    }",
        "detail": "distributed.logguer",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "distributed.logguer",
        "description": "distributed.logguer",
        "peekOfCode": "file_handler = logging.FileHandler(\"my_logs.txt\")\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(filename)s - %(lineno)d - %(message)s')\nfile_handler.setFormatter(formatter)\n# Configura el manejador de consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\n# Configura el logger raíz\nlogging.basicConfig(handlers=[file_handler, console_handler], level=logging.DEBUG)\n# Define un diccionario para almacenar los logs en JSON\nlogs_json = {}",
        "detail": "distributed.logguer",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": "distributed.logguer",
        "description": "distributed.logguer",
        "peekOfCode": "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(filename)s - %(lineno)d - %(message)s')\nfile_handler.setFormatter(formatter)\n# Configura el manejador de consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\n# Configura el logger raíz\nlogging.basicConfig(handlers=[file_handler, console_handler], level=logging.DEBUG)\n# Define un diccionario para almacenar los logs en JSON\nlogs_json = {}\n# Función para serializar los logs en JSON",
        "detail": "distributed.logguer",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "distributed.logguer",
        "description": "distributed.logguer",
        "peekOfCode": "console_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\n# Configura el logger raíz\nlogging.basicConfig(handlers=[file_handler, console_handler], level=logging.DEBUG)\n# Define un diccionario para almacenar los logs en JSON\nlogs_json = {}\n# Función para serializar los logs en JSON\ndef serialize_logs(logs_json, filename=\"logs.json\"):\n    with open(filename, 'w') as f:\n        json.dump(logs_json, f, indent=4)",
        "detail": "distributed.logguer",
        "documentation": {}
    },
    {
        "label": "logs_json",
        "kind": 5,
        "importPath": "distributed.logguer",
        "description": "distributed.logguer",
        "peekOfCode": "logs_json = {}\n# Función para serializar los logs en JSON\ndef serialize_logs(logs_json, filename=\"logs.json\"):\n    with open(filename, 'w') as f:\n        json.dump(logs_json, f, indent=4)\n# Crea una función para registrar mensajes con información adicional\ndef log_message(message, level=\"INFO\", extra_data={}):\n    \"\"\"\n    Registra un mensaje de log con información adicional.\n    \"\"\"",
        "detail": "distributed.logguer",
        "documentation": {}
    },
    {
        "label": "FIND_SUCCESSOR",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "FIND_SUCCESSOR = 1\nFIND_PREDECESSOR = 2\n#FIND_SUCCESSOR_WITHOUT_PREDECESSOR=10 # Busca el nodo que tiene sucesor y no predecesor el cual es el nodo \"0 \" por lo cual el nodo de mayor rango de la red debe buscarlo\nGET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "FIND_PREDECESSOR",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "FIND_PREDECESSOR = 2\n#FIND_SUCCESSOR_WITHOUT_PREDECESSOR=10 # Busca el nodo que tiene sucesor y no predecesor el cual es el nodo \"0 \" por lo cual el nodo de mayor rango de la red debe buscarlo\nGET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "GET_SUCCESSOR",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "GET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "GET_PREDECESSOR",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "GET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "NOTIFY",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "NOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "CHECK_PREDECESSOR",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "CHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "CLOSEST_PRECEDING_FINGER",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "CLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "STORE_KEY",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "STORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "RETRIEVE_KEY",
        "kind": 5,
        "importPath": "distributed.protocol_codes",
        "description": "distributed.protocol_codes",
        "peekOfCode": "RETRIEVE_KEY = 9",
        "detail": "distributed.protocol_codes",
        "documentation": {}
    },
    {
        "label": "BlockchainNode",
        "kind": 6,
        "importPath": "distributed.selection_lider_by_proof_of_work",
        "description": "distributed.selection_lider_by_proof_of_work",
        "peekOfCode": "class BlockchainNode:\n    def __init__(self, id, port):\n        self.id = id\n        self.port = int(port)\n        self.chain = []\n        self.create_genesis_block()\n        self.p = None\n    def create_genesis_block(self):\n        genesis_block = {\n            'index': 0,",
        "detail": "distributed.selection_lider_by_proof_of_work",
        "documentation": {}
    },
    {
        "label": "make_pow",
        "kind": 2,
        "importPath": "distributed.selection_lider_by_proof_of_work",
        "description": "distributed.selection_lider_by_proof_of_work",
        "peekOfCode": "def make_pow(node):\n    while True:\n        new_block = node.create_new_block('Some transaction data')\n        node.broadcast_block(new_block)\nif __name__ == '__main__':\n    node = BlockchainNode(ID, PUB_PORT)\n    node.start()",
        "detail": "distributed.selection_lider_by_proof_of_work",
        "documentation": {}
    },
    {
        "label": "HOST",
        "kind": 5,
        "importPath": "distributed.selection_lider_by_proof_of_work",
        "description": "distributed.selection_lider_by_proof_of_work",
        "peekOfCode": "HOST = '0.0.0.0'\nPUB_PORT = '8002'\nID = str(socket.gethostbyname(socket.gethostname()))\nDIFFICULTY = 6\nprint(f\"Running on {ID}\")\nclass BlockchainNode:\n    def __init__(self, id, port):\n        self.id = id\n        self.port = int(port)\n        self.chain = []",
        "detail": "distributed.selection_lider_by_proof_of_work",
        "documentation": {}
    },
    {
        "label": "PUB_PORT",
        "kind": 5,
        "importPath": "distributed.selection_lider_by_proof_of_work",
        "description": "distributed.selection_lider_by_proof_of_work",
        "peekOfCode": "PUB_PORT = '8002'\nID = str(socket.gethostbyname(socket.gethostname()))\nDIFFICULTY = 6\nprint(f\"Running on {ID}\")\nclass BlockchainNode:\n    def __init__(self, id, port):\n        self.id = id\n        self.port = int(port)\n        self.chain = []\n        self.create_genesis_block()",
        "detail": "distributed.selection_lider_by_proof_of_work",
        "documentation": {}
    },
    {
        "label": "ID",
        "kind": 5,
        "importPath": "distributed.selection_lider_by_proof_of_work",
        "description": "distributed.selection_lider_by_proof_of_work",
        "peekOfCode": "ID = str(socket.gethostbyname(socket.gethostname()))\nDIFFICULTY = 6\nprint(f\"Running on {ID}\")\nclass BlockchainNode:\n    def __init__(self, id, port):\n        self.id = id\n        self.port = int(port)\n        self.chain = []\n        self.create_genesis_block()\n        self.p = None",
        "detail": "distributed.selection_lider_by_proof_of_work",
        "documentation": {}
    },
    {
        "label": "DIFFICULTY",
        "kind": 5,
        "importPath": "distributed.selection_lider_by_proof_of_work",
        "description": "distributed.selection_lider_by_proof_of_work",
        "peekOfCode": "DIFFICULTY = 6\nprint(f\"Running on {ID}\")\nclass BlockchainNode:\n    def __init__(self, id, port):\n        self.id = id\n        self.port = int(port)\n        self.chain = []\n        self.create_genesis_block()\n        self.p = None\n    def create_genesis_block(self):",
        "detail": "distributed.selection_lider_by_proof_of_work",
        "documentation": {}
    },
    {
        "label": "vector_compare",
        "kind": 2,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "def vector_compare(vector1,vector2):\n    vector = [max(value) for value in zip(vector1,vector2)]\n    return vector\nP = {1:{}, 2:{}, 3:{}} # Inititalized an empty dictionary having 3 process\ninc = 0\nn1 = int(input(\"Enter the no. of events in Process 1 : \"))\ne1 = [i for i in range(1, n1 + 1)]\nP[1] = {key: [inc + key, 0, 0] for key in e1}\nprint(P[1])\nprint(\"\\n\")",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "P",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "P = {1:{}, 2:{}, 3:{}} # Inititalized an empty dictionary having 3 process\ninc = 0\nn1 = int(input(\"Enter the no. of events in Process 1 : \"))\ne1 = [i for i in range(1, n1 + 1)]\nP[1] = {key: [inc + key, 0, 0] for key in e1}\nprint(P[1])\nprint(\"\\n\")\nn2 = int(input(\"Enter the no. of events in Process 2 : \"))\ne2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "inc",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "inc = 0\nn1 = int(input(\"Enter the no. of events in Process 1 : \"))\ne1 = [i for i in range(1, n1 + 1)]\nP[1] = {key: [inc + key, 0, 0] for key in e1}\nprint(P[1])\nprint(\"\\n\")\nn2 = int(input(\"Enter the no. of events in Process 2 : \"))\ne2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "n1",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "n1 = int(input(\"Enter the no. of events in Process 1 : \"))\ne1 = [i for i in range(1, n1 + 1)]\nP[1] = {key: [inc + key, 0, 0] for key in e1}\nprint(P[1])\nprint(\"\\n\")\nn2 = int(input(\"Enter the no. of events in Process 2 : \"))\ne2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])\nprint(\"\\n\")",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "e1",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "e1 = [i for i in range(1, n1 + 1)]\nP[1] = {key: [inc + key, 0, 0] for key in e1}\nprint(P[1])\nprint(\"\\n\")\nn2 = int(input(\"Enter the no. of events in Process 2 : \"))\ne2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])\nprint(\"\\n\")\nn3 = int(input(\"Enter the no. of events in Process 3 : \"))",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "P[1]",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "P[1] = {key: [inc + key, 0, 0] for key in e1}\nprint(P[1])\nprint(\"\\n\")\nn2 = int(input(\"Enter the no. of events in Process 2 : \"))\ne2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])\nprint(\"\\n\")\nn3 = int(input(\"Enter the no. of events in Process 3 : \"))\ne3 = [i for i in range(1, n3 + 1)]",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "n2",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "n2 = int(input(\"Enter the no. of events in Process 2 : \"))\ne2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])\nprint(\"\\n\")\nn3 = int(input(\"Enter the no. of events in Process 3 : \"))\ne3 = [i for i in range(1, n3 + 1)]\nP[3] = {key: [0, 0, inc + key] for key in e3}\nprint(P[3])\nprint(\"\\n\")",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "e2",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "e2 = [i for i in range(1, n2 + 1)]\nP[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])\nprint(\"\\n\")\nn3 = int(input(\"Enter the no. of events in Process 3 : \"))\ne3 = [i for i in range(1, n3 + 1)]\nP[3] = {key: [0, 0, inc + key] for key in e3}\nprint(P[3])\nprint(\"\\n\")\ncomm = int(input(\"Enter the no of communication lines : \"))",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "P[2]",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "P[2] = {key: [0, inc + key, 0] for key in e2}\nprint(P[2])\nprint(\"\\n\")\nn3 = int(input(\"Enter the no. of events in Process 3 : \"))\ne3 = [i for i in range(1, n3 + 1)]\nP[3] = {key: [0, 0, inc + key] for key in e3}\nprint(P[3])\nprint(\"\\n\")\ncomm = int(input(\"Enter the no of communication lines : \"))\nprint(\"\\n\")",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "n3",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "n3 = int(input(\"Enter the no. of events in Process 3 : \"))\ne3 = [i for i in range(1, n3 + 1)]\nP[3] = {key: [0, 0, inc + key] for key in e3}\nprint(P[3])\nprint(\"\\n\")\ncomm = int(input(\"Enter the no of communication lines : \"))\nprint(\"\\n\")\nwhile inc < comm:\n    sent = int(input(\"Enter the sending process number : \"))\n    recv = int(input(\"Enter the receiving process number : \"))",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "e3",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "e3 = [i for i in range(1, n3 + 1)]\nP[3] = {key: [0, 0, inc + key] for key in e3}\nprint(P[3])\nprint(\"\\n\")\ncomm = int(input(\"Enter the no of communication lines : \"))\nprint(\"\\n\")\nwhile inc < comm:\n    sent = int(input(\"Enter the sending process number : \"))\n    recv = int(input(\"Enter the receiving process number : \"))\n    sent_event_no = int(input(\"Enter the sending event number : \"))",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "P[3]",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "P[3] = {key: [0, 0, inc + key] for key in e3}\nprint(P[3])\nprint(\"\\n\")\ncomm = int(input(\"Enter the no of communication lines : \"))\nprint(\"\\n\")\nwhile inc < comm:\n    sent = int(input(\"Enter the sending process number : \"))\n    recv = int(input(\"Enter the receiving process number : \"))\n    sent_event_no = int(input(\"Enter the sending event number : \"))\n    recv_event_no = int(input(\"Enter the receiving event number : \"))",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "comm",
        "kind": 5,
        "importPath": "distributed.vectorial_lamport",
        "description": "distributed.vectorial_lamport",
        "peekOfCode": "comm = int(input(\"Enter the no of communication lines : \"))\nprint(\"\\n\")\nwhile inc < comm:\n    sent = int(input(\"Enter the sending process number : \"))\n    recv = int(input(\"Enter the receiving process number : \"))\n    sent_event_no = int(input(\"Enter the sending event number : \"))\n    recv_event_no = int(input(\"Enter the receiving event number : \"))\n    if sent <= 3 and recv <= 3:\n        print (\"P{} --> P{}\".format(sent,recv))\n        new_vector = vector_compare(P[sent][sent_event_no],P[recv][recv_event_no])",
        "detail": "distributed.vectorial_lamport",
        "documentation": {}
    },
    {
        "label": "tarea_en_fondo",
        "kind": 2,
        "importPath": "examples.Ejemplo hilo demonio",
        "description": "examples.Ejemplo hilo demonio",
        "peekOfCode": "def tarea_en_fondo():\n    print(\"Hilo demonio iniciado\")\n    time.sleep(6)  # Este hilo dormiría durante 10 segundos\n    print(\"Hilo demonio despertando\")\n# Crear un hilo demonio\nhilo_demonio = threading.Thread(target=tarea_en_fondo)\nhilo_demonio.daemon = True  # Marcar el hilo como demonio\nhilo_demonio.start()\n# Ejecutar algo en el hilo principal\nprint(\"Ejecutando algo en el hilo principal\")",
        "detail": "examples.Ejemplo hilo demonio",
        "documentation": {}
    },
    {
        "label": "hilo_demonio",
        "kind": 5,
        "importPath": "examples.Ejemplo hilo demonio",
        "description": "examples.Ejemplo hilo demonio",
        "peekOfCode": "hilo_demonio = threading.Thread(target=tarea_en_fondo)\nhilo_demonio.daemon = True  # Marcar el hilo como demonio\nhilo_demonio.start()\n# Ejecutar algo en el hilo principal\nprint(\"Ejecutando algo en el hilo principal\")\ntime.sleep(5)  # Hacer que el hilo principal duerma durante 5 segundos\nprint(\"Programa principal terminando\")",
        "detail": "examples.Ejemplo hilo demonio",
        "documentation": {}
    },
    {
        "label": "hilo_demonio.daemon",
        "kind": 5,
        "importPath": "examples.Ejemplo hilo demonio",
        "description": "examples.Ejemplo hilo demonio",
        "peekOfCode": "hilo_demonio.daemon = True  # Marcar el hilo como demonio\nhilo_demonio.start()\n# Ejecutar algo en el hilo principal\nprint(\"Ejecutando algo en el hilo principal\")\ntime.sleep(5)  # Hacer que el hilo principal duerma durante 5 segundos\nprint(\"Programa principal terminando\")",
        "detail": "examples.Ejemplo hilo demonio",
        "documentation": {}
    },
    {
        "label": "Corpus",
        "kind": 6,
        "importPath": "src.Pre_Processing.Corpus",
        "description": "src.Pre_Processing.Corpus",
        "peekOfCode": "class Corpus:\n    def __init__(self,docs : List[Document], model : gensim.models.TfidfModel, dictionary : gensim.corpora.Dictionary, sim_matrix : gensim.similarities.MatrixSimilarity):\n        self.docs = docs\n        self.model = model\n        self.dictionary = dictionary\n        self.sim_matrix = sim_matrix\n    def add_documents(self, docs : List[Document]):\n        self.dictionary.add_documents([d.representation for d in docs])\ndef load_all_dates() -> Corpus :\n    sim_matrix = gensim.similarities.MatrixSimilarity.load(DATA_UBICATION + \"sim_matrix\")",
        "detail": "src.Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "load_all_dates",
        "kind": 2,
        "importPath": "src.Pre_Processing.Corpus",
        "description": "src.Pre_Processing.Corpus",
        "peekOfCode": "def load_all_dates() -> Corpus :\n    sim_matrix = gensim.similarities.MatrixSimilarity.load(DATA_UBICATION + \"sim_matrix\")\n    dictionary = gensim.corpora.Dictionary.load(DATA_UBICATION + \"word_id_dic\")\n    model = gensim.models.TfidfModel.load(DATA_UBICATION + \"tfidf_model\")\n    docs = read_documents()\n    return Corpus(docs, model, dictionary, sim_matrix)\ndef save_all_dates(corpus : Corpus):\n    corpus.sim_matrix.save(DATA_UBICATION + \"sim_matrix\")\n    corpus.dictionary.save(DATA_UBICATION + \"word_id_dic\")\n    corpus.model.save(DATA_UBICATION + \"tfidf_model\")",
        "detail": "src.Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "save_all_dates",
        "kind": 2,
        "importPath": "src.Pre_Processing.Corpus",
        "description": "src.Pre_Processing.Corpus",
        "peekOfCode": "def save_all_dates(corpus : Corpus):\n    corpus.sim_matrix.save(DATA_UBICATION + \"sim_matrix\")\n    corpus.dictionary.save(DATA_UBICATION + \"word_id_dic\")\n    corpus.model.save(DATA_UBICATION + \"tfidf_model\")",
        "detail": "src.Pre_Processing.Corpus",
        "documentation": {}
    },
    {
        "label": "to_BoW",
        "kind": 2,
        "importPath": "src.Pre_Processing.Doc_Term_Matrix",
        "description": "src.Pre_Processing.Doc_Term_Matrix",
        "peekOfCode": "def to_BoW(doc : Document, word_id_dictionary : gensim.corpora.Dictionary):\n    doc.representation = word_id_dictionary.doc2bow(doc.representation)\ndef build_doc_term_matrix(docs : List[Document]):\n    for doc in docs:\n        clean_document(doc)\n    word_id_dictionary = build_words_id_dictionary(docs)\n    for doc in docs:\n        to_BoW(doc,word_id_dictionary)\n    doc_term_matrix = [doc.representation for doc in docs]\n    return word_id_dictionary, doc_term_matrix",
        "detail": "src.Pre_Processing.Doc_Term_Matrix",
        "documentation": {}
    },
    {
        "label": "build_doc_term_matrix",
        "kind": 2,
        "importPath": "src.Pre_Processing.Doc_Term_Matrix",
        "description": "src.Pre_Processing.Doc_Term_Matrix",
        "peekOfCode": "def build_doc_term_matrix(docs : List[Document]):\n    for doc in docs:\n        clean_document(doc)\n    word_id_dictionary = build_words_id_dictionary(docs)\n    for doc in docs:\n        to_BoW(doc,word_id_dictionary)\n    doc_term_matrix = [doc.representation for doc in docs]\n    return word_id_dictionary, doc_term_matrix",
        "detail": "src.Pre_Processing.Doc_Term_Matrix",
        "documentation": {}
    },
    {
        "label": "Document",
        "kind": 6,
        "importPath": "src.Pre_Processing.Document",
        "description": "src.Pre_Processing.Document",
        "peekOfCode": "class Document:\n    def __init__(self, title : str, text : str):\n        self.title = title\n        self.text = text\n        self.representation = None",
        "detail": "src.Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DOCUMENTS_UBICATION",
        "kind": 5,
        "importPath": "src.Pre_Processing.Document",
        "description": "src.Pre_Processing.Document",
        "peekOfCode": "DOCUMENTS_UBICATION = \"data/documents/\"\nDATA_UBICATION = \"data/data/\"\nclass Document:\n    def __init__(self, title : str, text : str):\n        self.title = title\n        self.text = text\n        self.representation = None",
        "detail": "src.Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "DATA_UBICATION",
        "kind": 5,
        "importPath": "src.Pre_Processing.Document",
        "description": "src.Pre_Processing.Document",
        "peekOfCode": "DATA_UBICATION = \"data/data/\"\nclass Document:\n    def __init__(self, title : str, text : str):\n        self.title = title\n        self.text = text\n        self.representation = None",
        "detail": "src.Pre_Processing.Document",
        "documentation": {}
    },
    {
        "label": "clean_document",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Cleaner",
        "description": "src.Pre_Processing.Document_Cleaner",
        "peekOfCode": "def clean_document(doc : Document):\n    tokenize_doc(doc)\n    remove_noise(doc)\n    remove_stop_words(doc)\n    morphological_reduce(doc)    \ndef tokenize_doc(doc : Document):\n    doc.representation = [token for token in nlp(doc.text)]\ndef remove_noise(doc : Document):\n    doc.representation = [token for token in doc.representation if token.is_alpha]\ndef remove_stop_words(doc : Document):",
        "detail": "src.Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "tokenize_doc",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Cleaner",
        "description": "src.Pre_Processing.Document_Cleaner",
        "peekOfCode": "def tokenize_doc(doc : Document):\n    doc.representation = [token for token in nlp(doc.text)]\ndef remove_noise(doc : Document):\n    doc.representation = [token for token in doc.representation if token.is_alpha]\ndef remove_stop_words(doc : Document):\n    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n    doc.representation = [token for token in doc.representation if token.text not in stop_words]\ndef morphological_reduce(doc : Document):\n        doc.representation = [token.lemma_ for token in doc.representation]",
        "detail": "src.Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "remove_noise",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Cleaner",
        "description": "src.Pre_Processing.Document_Cleaner",
        "peekOfCode": "def remove_noise(doc : Document):\n    doc.representation = [token for token in doc.representation if token.is_alpha]\ndef remove_stop_words(doc : Document):\n    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n    doc.representation = [token for token in doc.representation if token.text not in stop_words]\ndef morphological_reduce(doc : Document):\n        doc.representation = [token.lemma_ for token in doc.representation]",
        "detail": "src.Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "remove_stop_words",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Cleaner",
        "description": "src.Pre_Processing.Document_Cleaner",
        "peekOfCode": "def remove_stop_words(doc : Document):\n    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n    doc.representation = [token for token in doc.representation if token.text not in stop_words]\ndef morphological_reduce(doc : Document):\n        doc.representation = [token.lemma_ for token in doc.representation]",
        "detail": "src.Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "morphological_reduce",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Cleaner",
        "description": "src.Pre_Processing.Document_Cleaner",
        "peekOfCode": "def morphological_reduce(doc : Document):\n        doc.representation = [token.lemma_ for token in doc.representation]",
        "detail": "src.Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "nlp",
        "kind": 5,
        "importPath": "src.Pre_Processing.Document_Cleaner",
        "description": "src.Pre_Processing.Document_Cleaner",
        "peekOfCode": "nlp = spacy.load(\"en_core_web_sm\")\ndef clean_document(doc : Document):\n    tokenize_doc(doc)\n    remove_noise(doc)\n    remove_stop_words(doc)\n    morphological_reduce(doc)    \ndef tokenize_doc(doc : Document):\n    doc.representation = [token for token in nlp(doc.text)]\ndef remove_noise(doc : Document):\n    doc.representation = [token for token in doc.representation if token.is_alpha]",
        "detail": "src.Pre_Processing.Document_Cleaner",
        "documentation": {}
    },
    {
        "label": "read_documents",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Folder_Access",
        "description": "src.Pre_Processing.Document_Folder_Access",
        "peekOfCode": "def read_documents():\n    docs = []\n    with os.scandir(DOCUMENTS_UBICATION) as files:\n        for file in files:\n            docs.append(read_document(file.name))\n    return docs\ndef read_document(title):\n    with open(DOCUMENTS_UBICATION+title,'r') as file:\n        text = file.read()\n    return Document(title, text)",
        "detail": "src.Pre_Processing.Document_Folder_Access",
        "documentation": {}
    },
    {
        "label": "read_document",
        "kind": 2,
        "importPath": "src.Pre_Processing.Document_Folder_Access",
        "description": "src.Pre_Processing.Document_Folder_Access",
        "peekOfCode": "def read_document(title):\n    with open(DOCUMENTS_UBICATION+title,'r') as file:\n        text = file.read()\n    return Document(title, text)",
        "detail": "src.Pre_Processing.Document_Folder_Access",
        "documentation": {}
    },
    {
        "label": "prepare_corpus",
        "kind": 2,
        "importPath": "src.Pre_Processing.Processor",
        "description": "src.Pre_Processing.Processor",
        "peekOfCode": "def prepare_corpus():\n    docs = read_documents()\n    save_docs_names(docs)\n    current_titles = [d.title for d in docs]\n    procesed_titles = load_docs_names()\n    is_eq = utils.is_eq(current_titles,procesed_titles)\n    if not is_eq:\n        process_documents(docs)\n        save_docs_names(docs)\n    return load_all_dates()",
        "detail": "src.Pre_Processing.Processor",
        "documentation": {}
    },
    {
        "label": "process_documents",
        "kind": 2,
        "importPath": "src.Pre_Processing.Processor",
        "description": "src.Pre_Processing.Processor",
        "peekOfCode": "def process_documents(docs : List[Document]):\n    word_id_dictionary, doc_term_matrix = build_doc_term_matrix(docs)\n    model = build_tf_idf_model(docs)\n    sim_matrix = build_similarity_matrix(model, doc_term_matrix)\n    corpus = Corpus(docs,model,word_id_dictionary,sim_matrix)\n    save_all_dates(corpus)\ndef save_docs_names(docs : List[Document]):\n    with open(DATA_UBICATION + \"docs_names\",'w') as file:\n        json.dump([d.title for d in docs],file)\ndef load_docs_names():",
        "detail": "src.Pre_Processing.Processor",
        "documentation": {}
    },
    {
        "label": "save_docs_names",
        "kind": 2,
        "importPath": "src.Pre_Processing.Processor",
        "description": "src.Pre_Processing.Processor",
        "peekOfCode": "def save_docs_names(docs : List[Document]):\n    with open(DATA_UBICATION + \"docs_names\",'w') as file:\n        json.dump([d.title for d in docs],file)\ndef load_docs_names():\n    with open(DATA_UBICATION + \"docs_names\",'r') as file:\n        return json.load(file)",
        "detail": "src.Pre_Processing.Processor",
        "documentation": {}
    },
    {
        "label": "load_docs_names",
        "kind": 2,
        "importPath": "src.Pre_Processing.Processor",
        "description": "src.Pre_Processing.Processor",
        "peekOfCode": "def load_docs_names():\n    with open(DATA_UBICATION + \"docs_names\",'r') as file:\n        return json.load(file)",
        "detail": "src.Pre_Processing.Processor",
        "documentation": {}
    },
    {
        "label": "build_similarity_matrix",
        "kind": 2,
        "importPath": "src.Pre_Processing.Similarity_Matrix",
        "description": "src.Pre_Processing.Similarity_Matrix",
        "peekOfCode": "def build_similarity_matrix(model : gensim.models.TfidfModel, doc_term_matrix : List[Tuple[int,int]]) -> gensim.similarities.MatrixSimilarity:\n    #sim_matrix = gensim.similarities.MatrixSimilarity(model[doc_term_matrix])\n    sim_matrix = gensim.similarities.MatrixSimilarity(doc_term_matrix)\n    return sim_matrix",
        "detail": "src.Pre_Processing.Similarity_Matrix",
        "documentation": {}
    },
    {
        "label": "build_tf_idf_model",
        "kind": 2,
        "importPath": "src.Pre_Processing.TF_IDF",
        "description": "src.Pre_Processing.TF_IDF",
        "peekOfCode": "def build_tf_idf_model(documents : List[Document]):\n    corpus = [doc.representation for doc in documents]\n    tfidf_model = gensim.models.TfidfModel(corpus, normalize = True)\n    return tfidf_model",
        "detail": "src.Pre_Processing.TF_IDF",
        "documentation": {}
    },
    {
        "label": "build_words_id_dictionary",
        "kind": 2,
        "importPath": "src.Pre_Processing.Word_Id_Dictionary",
        "description": "src.Pre_Processing.Word_Id_Dictionary",
        "peekOfCode": "def build_words_id_dictionary(docs : List[Document]) -> gensim.corpora.Dictionary:\n    words_id_dictionary = gensim.corpora.Dictionary([doc.representation for doc in docs])\n    words_id_dictionary.save(DATA_UBICATION+\"word_id_dic\")\n    return words_id_dictionary",
        "detail": "src.Pre_Processing.Word_Id_Dictionary",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 2,
        "importPath": "src.Search.Search",
        "description": "src.Search.Search",
        "peekOfCode": "def search(query : str, corpus : Corpus) -> List[Document]:\n    query = Document('query', query)\n    clean_document(query)\n    query_bow = corpus.dictionary.doc2bow(query.representation)\n    #sims = corpus.sim_matrix[corpus.model[query_bow]]\n    sims = corpus.sim_matrix[query_bow]\n    searched = []\n    for index in sorted(enumerate(sims), key=lambda item: -item[1])[:3]:\n        searched.append(corpus.docs[index[0]])\n    return searched",
        "detail": "src.Search.Search",
        "documentation": {}
    },
    {
        "label": "get_documents",
        "kind": 2,
        "importPath": "src.To_Test.documents",
        "description": "src.To_Test.documents",
        "peekOfCode": "def get_documents(dataset_name : str):\n    dataset = ir_datasets.load(dataset_name)\n    return [Document(doc.title, doc.text) for doc in dataset.docs_iter()]\ndef get_random_documents(num_docs = 1,dataset_name = \"cranfield\"):\n    document = get_documents(dataset_name)\n    return random.sample(document,num_docs)\ndef add_document(doc : Document):\n    with open(DOCUMENTS_UBICATION+doc.title,'w') as file:\n        file.write(doc.text)\ndef add_random_documents(num_docs):",
        "detail": "src.To_Test.documents",
        "documentation": {}
    },
    {
        "label": "get_random_documents",
        "kind": 2,
        "importPath": "src.To_Test.documents",
        "description": "src.To_Test.documents",
        "peekOfCode": "def get_random_documents(num_docs = 1,dataset_name = \"cranfield\"):\n    document = get_documents(dataset_name)\n    return random.sample(document,num_docs)\ndef add_document(doc : Document):\n    with open(DOCUMENTS_UBICATION+doc.title,'w') as file:\n        file.write(doc.text)\ndef add_random_documents(num_docs):\n    docs = get_random_documents(num_docs)\n    for d in docs: add_document(d)",
        "detail": "src.To_Test.documents",
        "documentation": {}
    },
    {
        "label": "add_document",
        "kind": 2,
        "importPath": "src.To_Test.documents",
        "description": "src.To_Test.documents",
        "peekOfCode": "def add_document(doc : Document):\n    with open(DOCUMENTS_UBICATION+doc.title,'w') as file:\n        file.write(doc.text)\ndef add_random_documents(num_docs):\n    docs = get_random_documents(num_docs)\n    for d in docs: add_document(d)",
        "detail": "src.To_Test.documents",
        "documentation": {}
    },
    {
        "label": "add_random_documents",
        "kind": 2,
        "importPath": "src.To_Test.documents",
        "description": "src.To_Test.documents",
        "peekOfCode": "def add_random_documents(num_docs):\n    docs = get_random_documents(num_docs)\n    for d in docs: add_document(d)",
        "detail": "src.To_Test.documents",
        "documentation": {}
    },
    {
        "label": "corpus",
        "kind": 5,
        "importPath": "src.main",
        "description": "src.main",
        "peekOfCode": "corpus = prepare_corpus()\nquery = st.text_input(\"Introduce your query\")\nif query:\n    for d in search(query,corpus):\n        st.write(d.title)",
        "detail": "src.main",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "src.main",
        "description": "src.main",
        "peekOfCode": "query = st.text_input(\"Introduce your query\")\nif query:\n    for d in search(query,corpus):\n        st.write(d.title)",
        "detail": "src.main",
        "documentation": {}
    },
    {
        "label": "compare_arrays",
        "kind": 2,
        "importPath": "src.utils",
        "description": "src.utils",
        "peekOfCode": "def compare_arrays(array1, array2):\n    a1 = set(array1)\n    a2 = set(array2)\n    a1_only = a1.difference(a2)\n    a2_only = a2.difference(a1)\n    return list(a1_only), list(a2_only)\ndef is_eq(array1, array2):\n    a1_only, a2_only = compare_arrays(array1, array2)\n    return (len(a1_only) == 0) and (len(a2_only) == 0)",
        "detail": "src.utils",
        "documentation": {}
    },
    {
        "label": "is_eq",
        "kind": 2,
        "importPath": "src.utils",
        "description": "src.utils",
        "peekOfCode": "def is_eq(array1, array2):\n    a1_only, a2_only = compare_arrays(array1, array2)\n    return (len(a1_only) == 0) and (len(a2_only) == 0)",
        "detail": "src.utils",
        "documentation": {}
    },
    {
        "label": "ChordNodeReference",
        "kind": 6,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "class ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n    # Internal method to send data to the referenced node\n    def _send_data(self, op: int, data: str = None) -> bytes:\n        try:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                s.connect((self.ip, self.port))",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "ChordNode",
        "kind": 6,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "class ChordNode:\n    def __init__(self, ip: str, port: int = 8001, m: int = 160):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n        self.ref = ChordNodeReference(self.ip, self.port)\n        self.succ = self.ref  # Initial successor is itself\n        self.pred = None  # Initially no predecessor\n        self.m = m  # Number of bits in the hash/key space\n        self.finger = [self.ref] * self.m  # Finger table",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "getShaRepr",
        "kind": 2,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "def getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n    # Internal method to send data to the referenced node\n    def _send_data(self, op: int, data: str = None) -> bytes:",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "FIND_SUCCESSOR",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "FIND_SUCCESSOR = 1\nFIND_PREDECESSOR = 2\nGET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "FIND_PREDECESSOR",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "FIND_PREDECESSOR = 2\nGET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "GET_SUCCESSOR",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "GET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "GET_PREDECESSOR",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "GET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "NOTIFY",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "NOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "CHECK_PREDECESSOR",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "CHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "CLOSEST_PRECEDING_FINGER",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "CLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "STORE_KEY",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "STORE_KEY = 8\nRETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "RETRIEVE_KEY",
        "kind": 5,
        "importPath": "test.chord_replication",
        "description": "test.chord_replication",
        "peekOfCode": "RETRIEVE_KEY = 9\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port",
        "detail": "test.chord_replication",
        "documentation": {}
    },
    {
        "label": "some_function",
        "kind": 2,
        "importPath": "test.example_logger",
        "description": "test.example_logger",
        "peekOfCode": "def some_function():\n    app_logger.info('Esta es una información de log')\n    try:\n        # Código que podría lanzar una excepción\n        result = 10 / 0\n    except Exception as e:\n        app_logger.error('Se produjo una excepción', exc_info=True)\nif __name__ == \"__main__\":\n    app_logger.info('Inicio de la aplicación')\n    some_function()",
        "detail": "test.example_logger",
        "documentation": {}
    },
    {
        "label": "JSONFormatter",
        "kind": 6,
        "importPath": "test.logger",
        "description": "test.logger",
        "peekOfCode": "class JSONFormatter(logging.Formatter):\n    def format(self, record):\n        log_record = {\n            'timestamp': self.formatTime(record, self.datefmt),\n            'level': record.levelname,\n            'message': record.getMessage(),\n            'name': record.name,\n            'filename': record.filename,\n            'funcName': record.funcName,\n            'lineno': record.lineno,",
        "detail": "test.logger",
        "documentation": {}
    },
    {
        "label": "setup_logger",
        "kind": 2,
        "importPath": "test.logger",
        "description": "test.logger",
        "peekOfCode": "def setup_logger(name, log_file=None, level=logging.INFO, to_console=False):\n    handlers = []\n    if log_file:\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setFormatter(JSONFormatter())\n        handlers.append(file_handler)\n    if to_console:\n        console_handler = logging.StreamHandler()\n        console_handler.setFormatter(JSONFormatter())\n        handlers.append(console_handler)",
        "detail": "test.logger",
        "documentation": {}
    },
    {
        "label": "app_logger",
        "kind": 5,
        "importPath": "test.logger",
        "description": "test.logger",
        "peekOfCode": "app_logger = setup_logger('app_logger', 'app_log.json', to_console=True)",
        "detail": "test.logger",
        "documentation": {}
    },
    {
        "label": "ChordNodeReference",
        "kind": 6,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "class ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n    # Internal method to send data to the referenced node\n    def _send_data(self, op: int, data: str = None) -> bytes:\n        #print(f'mandando la data con op{op} - y data {data}')\n        try:\n            context = zmq.Context()",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "ChordNode",
        "kind": 6,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "class ChordNode:\n    def __init__(self, ip: str, port: int = 8001, m: int = 160): #m=160\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n        self.ref:ChordNodeReference = ChordNodeReference(self.ip, self.port)\n        self.succ:ChordNodeReference = self.ref  # Initial successor is itself\n        self.pred:ChordNodeReference = None  # Initially no predecessor\n        self.m = m  # Number of bits in the hash/key space\n        self.finger = [self.ref] * self.m  # Finger table",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "getShaRepr",
        "kind": 2,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "def getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port\n    # Internal method to send data to the referenced node\n    def _send_data(self, op: int, data: str = None) -> bytes:",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "FIND_SUCCESSOR",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "FIND_SUCCESSOR = 1\nFIND_PREDECESSOR = 2\nFIND_SUCCESSOR_WITHOUT_PREDECESSOR=10 # Busca el nodo que tiene sucesor y no predecesor el cual es el nodo \"0 \" por lo cual el nodo de mayor rango de la red debe buscarlo\nGET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "FIND_PREDECESSOR",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "FIND_PREDECESSOR = 2\nFIND_SUCCESSOR_WITHOUT_PREDECESSOR=10 # Busca el nodo que tiene sucesor y no predecesor el cual es el nodo \"0 \" por lo cual el nodo de mayor rango de la red debe buscarlo\nGET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "GET_SUCCESSOR",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "GET_SUCCESSOR = 3\nGET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "GET_PREDECESSOR",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "GET_PREDECESSOR = 4\nNOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "NOTIFY",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "NOTIFY = 5\nCHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "CHECK_PREDECESSOR",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "CHECK_PREDECESSOR = 6\nCLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "CLOSEST_PRECEDING_FINGER",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "CLOSEST_PRECEDING_FINGER = 7\nSTORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "STORE_KEY",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "STORE_KEY = 8\nRETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "RETRIEVE_KEY",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "RETRIEVE_KEY = 9\nUPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "UPDATE_KEY",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "UPDATE_KEY = 11\nDELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip",
        "detail": "test.new_chrod",
        "documentation": {}
    },
    {
        "label": "DELETE_KEY",
        "kind": 5,
        "importPath": "test.new_chrod",
        "description": "test.new_chrod",
        "peekOfCode": "DELETE_KEY = 12\n# Function to hash a string using SHA-1 and return its integer representation\ndef getShaRepr(data: str):\n    return int(hashlib.sha1(data.encode()).hexdigest(), 16)\n# Class to reference a Chord node\nclass ChordNodeReference:\n    def __init__(self, ip: str, port: int = 8001):\n        self.id = getShaRepr(ip)\n        self.ip = ip\n        self.port = port",
        "detail": "test.new_chrod",
        "documentation": {}
    }
]